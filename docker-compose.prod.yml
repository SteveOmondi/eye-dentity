version: '3.8'

# Production Docker Compose - Uses existing PostgreSQL database
# This configuration connects to your existing PostgreSQL instance

services:
  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    image: ghcr.io/${GITHUB_REPOSITORY}:latest
    container_name: eyedentity-api-prod
    restart: unless-stopped
    ports:
      - "${API_PORT:-3000}:3000"
    environment:
      # Database - connects to your existing PostgreSQL
      # Format: postgresql://username:password@host:port/database
      DATABASE_URL: ${DATABASE_URL}

      # Authentication
      JWT_SECRET: ${JWT_SECRET}

      # Stripe Payment
      STRIPE_SECRET_KEY: ${STRIPE_SECRET_KEY}
      STRIPE_WEBHOOK_SECRET: ${STRIPE_WEBHOOK_SECRET}
      STRIPE_PUBLISHABLE_KEY: ${STRIPE_PUBLISHABLE_KEY}

      # AI Services
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}

      # Cloud Storage (AWS S3 or compatible)
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_REGION: ${AWS_REGION:-us-east-1}
      S3_BUCKET_NAME: ${S3_BUCKET_NAME}

      # Application URLs
      FRONTEND_URL: ${FRONTEND_URL:-https://eyedentity.com}
      BACKEND_URL: ${BACKEND_URL:-https://api.eyedentity.com}

      # Marketing Platform APIs
      META_APP_ID: ${META_APP_ID}
      META_APP_SECRET: ${META_APP_SECRET}
      META_ACCESS_TOKEN: ${META_ACCESS_TOKEN}
      META_PIXEL_ID: ${META_PIXEL_ID}

      LINKEDIN_CLIENT_ID: ${LINKEDIN_CLIENT_ID}
      LINKEDIN_CLIENT_SECRET: ${LINKEDIN_CLIENT_SECRET}

      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET}
      GOOGLE_DEVELOPER_TOKEN: ${GOOGLE_DEVELOPER_TOKEN}

      # Notifications
      TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN}
      TELEGRAM_ADMIN_CHAT_ID: ${TELEGRAM_ADMIN_CHAT_ID}

      # Email (optional)
      SMTP_HOST: ${SMTP_HOST}
      SMTP_PORT: ${SMTP_PORT:-587}
      SMTP_USER: ${SMTP_USER}
      SMTP_PASSWORD: ${SMTP_PASSWORD}
      FROM_EMAIL: ${FROM_EMAIL}

      # Redis (optional)
      REDIS_URL: ${REDIS_URL:-redis://redis:6379}

      # Node Environment
      NODE_ENV: production
      PORT: 3000

    volumes:
      # Persistent uploads directory
      - ./uploads:/app/uploads
      # Application logs
      - ./logs:/app/logs

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

    # If your existing PostgreSQL is in a Docker network, uncomment and configure:
    # networks:
    #   - your_existing_network

  # Redis for caching and job queues (recommended)
  redis:
    image: redis:7-alpine
    container_name: eyedentity-redis-prod
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    command: >
      redis-server
      --appendonly yes
      --requirepass ${REDIS_PASSWORD:-}
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # Nginx Reverse Proxy (optional - remove if using external load balancer)
  nginx:
    image: nginx:alpine
    container_name: eyedentity-nginx-prod
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./uploads:/var/www/uploads:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - backend
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  redis_data:
    driver: local
  nginx_logs:
    driver: local

# Uncomment if your existing PostgreSQL is in a custom Docker network
# networks:
#   your_existing_network:
#     external: true
#     name: your_network_name
